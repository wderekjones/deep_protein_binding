{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Methods for Molecular Property Prediction\n",
    "*by: Derek Jones*\n",
    "\n",
    "This script implements methods in order to benchmark the performance of the neural fingerprinting methods for the\n",
    "    task of predicting dragon features from the smiles input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool, Queue\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "\n",
    "targets = [\"Hy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_file,fp_radius=2, fp_length=1024, targets=None, scaling=None, corrupt_path=None):\n",
    "    cols = [\"receptor\", \"drugID\", \"smiles\", \"label\"] + targets\n",
    "    print(\"loading data...\")\n",
    "    data = pd.read_csv(csv_file, usecols=cols)\n",
    "    corrupt_compound_df = pd.read_csv(corrupt_path)\n",
    "    data = data[~data.drugID.isin(corrupt_compound_df.drugID)]\n",
    "    if scaling == \"std\":\n",
    "        print(\"standardizing targets...\")\n",
    "        data[targets] = StandardScaler().fit_transform(data[targets])\n",
    "    elif scaling == \"norm\":\n",
    "        print(\"normalizing targets...\")\n",
    "        data[targets] = Normalizer().fit_transform(data[targets])\n",
    "    elif scaling is not None:\n",
    "        raise Exception(\"preprocessing method not implemented.\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_mol_job(smile):\n",
    "    return Chem.MolFromSmiles(smile)\n",
    "\n",
    "def get_fp_job(mol, fp_radius=2, nBits=1024):\n",
    "    return AllChem.GetMorganFingerprintAsBitVect(mol, fp_radius, nBits=nBits)\n",
    "\n",
    "def get_fp_data_job(fp):\n",
    "    x = np.ones(fp.GetNumBits())\n",
    "    DataStructs.ConvertToNumpyArray(fp,x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_fp_data(data):\n",
    "    return pd.DataFrame([get_fp_data_job(get_fp_job(get_mol_job(smile))) for smile in data[\"smiles\"]])\n",
    "\n",
    "\n",
    "def parallelize(data, func, workers, chunksize=10):\n",
    "    data_split = np.array_split(data, chunksize)\n",
    "    print(\"creating worker pool...\")\n",
    "    pool = Pool(processes=workers)\n",
    "    new_data = pd.concat(pool.map(func, data_split))  # may need special function for feeding multiple args\n",
    "    print(\"closing worker pool...\")\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "standardizing targets...\n"
     ]
    }
   ],
   "source": [
    "data = load_data(csv_file=\"/scratch/wdjo224/data/deep_protein_binding/kinase_no_duplicates_with_smiles.csv\",\n",
    "              corrupt_path=\"/scratch/wdjo224/data/deep_protein_binding/corrupt_inputs.csv\", targets=targets,\n",
    "              scaling=\"std\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing fingerprints...\n",
      "creating worker pool...\n",
      "closing worker pool...\n",
      "preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"computing fingerprints...\")\n",
    "fps = parallelize(func=get_fp_data, data=data, workers=10, chunksize=4)\n",
    "print(\"preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wdjo224/anaconda3/envs/deep_protein_binding/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', max_iter=10, n_iter=None, penalty='l2',\n",
       "       power_t=0.25, random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "train_idxs = np.fromfile(\"/scratch/wdjo224/deep_protein_binding/src/train.npy\", dtype=np.int)\n",
    "test_idxs = np.fromfile(\"/scratch/wdjo224/deep_protein_binding/src/test.npy\", dtype=np.int)\n",
    "\n",
    "# model = LinearRegression(n_jobs=2)\n",
    "\n",
    "x_train = fps.iloc[train_idxs].as_matrix()\n",
    "y_train = data[targets].iloc[train_idxs].as_matrix()\n",
    "x_test = fps.iloc[test_idxs].as_matrix()\n",
    "y_test = data[targets].iloc[test_idxs].as_matrix()\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test r2: 0.6922587539242938\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x_test)\n",
    "\n",
    "print(\"test r2: {}\".format(r2_score(y_pred=preds, y_true=y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_protein_binding",
   "language": "python",
   "name": "deep_protein_binding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
